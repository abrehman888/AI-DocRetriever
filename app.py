import streamlit as st
from qdrant_client import QdrantClient
from langchain.embeddings import HuggingFaceEmbeddings
from langchain_qdrant import QdrantVectorStore
import openai
from langchain.chains import create_retrieval_chain
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from operator import itemgetter

# Set page configuration for title and icon
st.set_page_config(page_title="Chat with Xeven Solution ", page_icon=":speech_balloon:")

# Load environment variables
qdrant_url = st.secrets["QDRANT_URL"]
qdrant_key = st.secrets["QDRANT_API_KEY"]
openai.api_key = st.secrets["OPENAI_API_KEY"]
collection_name = st.secrets["Collection_Name"]
llm_name = "gpt-4o-mini"

# Initialize embedding model
embed_model = HuggingFaceEmbeddings(model_name='BAAI/bge-small-en-v1.5')

# Create a QdrantClient instance
client = QdrantClient(url=qdrant_url, api_key=qdrant_key)

# Initialize QdrantVectorStore
qdrant = QdrantVectorStore(client=client, embedding=embed_model, collection_name=collection_name)

# Custom CSS for enhanced styling
st.markdown("""
Â  Â  <style>
Â  Â  Â  Â  body {
Â  Â  Â  Â  Â  Â  font-family: 'Open Sans', sans-serif;
Â  Â  Â  Â  Â  Â  background-color: #f7f9fc;
Â  Â  Â  Â  }

Â  Â  Â  Â  .header-title {
Â  Â  Â  Â  Â  Â  display: flex;
Â  Â  Â  Â  Â  Â  align-items: center;
Â  Â  Â  Â  Â  Â  gap: 15px;
Â  Â  Â  Â  Â  Â  font-size: 32px;
Â  Â  Â  Â  Â  Â  font-weight: bold;
Â  Â  Â  Â  Â  Â  color: #333;
Â  Â  Â  Â  }
Â  Â  Â  Â  .logo-img {
Â  Â  Â  Â  Â  Â  width: 50px;
Â  Â  Â  Â  }

Â  Â  Â  Â  .input-area {
Â  Â  Â  Â  Â  Â  padding: 15px;
Â  Â  Â  Â  Â  Â  border: 1px solid #ddd;
Â  Â  Â  Â  Â  Â  border-radius: 10px;
Â  Â  Â  Â  Â  Â  background-color: #fff;
Â  Â  Â  Â  Â  Â  box-shadow: 0px 2px 10px rgba(0, 0, 0, 0.1);
Â  Â  Â  Â  }
Â  Â  Â  Â  .stTextInput, .stButton button {
Â  Â  Â  Â  Â  Â  font-size: 18px;
Â  Â  Â  Â  }
Â  Â  Â  Â  .stTextInput {
Â  Â  Â  Â  Â  Â  padding: 10px;
Â  Â  Â  Â  Â  Â  border-radius: 5px;
Â  Â  Â  Â  }

Â  Â  Â  Â  .response-bubble {
Â  Â  Â  Â  Â  Â  margin-top: 10px;
Â  Â  Â  Â  Â  Â  padding: 15px;
Â  Â  Â  Â  Â  Â  background-color: #e3f2fd;
Â  Â  Â  Â  Â  Â  border-radius: 10px;
Â  Â  Â  Â  Â  Â  color: #333;
Â  Â  Â  Â  }

Â  Â  Â  Â  .stButton button {
Â  Â  Â  Â  Â  Â  background-color: #4285f4;
Â  Â  Â  Â  Â  Â  color: white;
Â  Â  Â  Â  Â  Â  border-radius: 5px;
Â  Â  Â  Â  Â  Â  padding: 10px 15px;
Â  Â  Â  Â  Â  Â  font-weight: bold;
Â  Â  Â  Â  Â  Â  transition: background-color 0.3s;
Â  Â  Â  Â  }
Â  Â  Â  Â  .stButton button:hover {
Â  Â  Â  Â  Â  Â  background-color: #1a73e8;
Â  Â  Â  Â  }

Â  Â  Â  Â  .footer {
Â  Â  Â  Â  Â  Â  text-align: center;
Â  Â  Â  Â  Â  Â  margin-top: 40px;
Â  Â  Â  Â  Â  Â  padding-top: 20px;
Â  Â  Â  Â  Â  Â  border-top: 1px solid #ddd;
Â  Â  Â  Â  Â  Â  font-size: 14px;
Â  Â  Â  Â  Â  Â  color: #888;
Â  Â  Â  Â  }

        /* Highlight the name */
        .highlighted-name {
            font-weight: bold;
            color: #007bff;
        }
Â  Â  </style>
""", unsafe_allow_html=True)

# Streamlit UI
st.markdown('<div class="header-title"><img src="https://raw.githubusercontent.com/abrehman888/RAG/refs/heads/main/xevensolutions_logo.jpeg" class="logo-img" />Chat with Xeven Solution</div>', unsafe_allow_html=True)
st.write("**Developed by <span class='highlighted-name'>Abdul Rehman</span>**")

st.write("Ask your question below:")

def format_docs(docs):
  return "\n\n".join(doc.page_content for doc in docs)

# Set up the prompt template
prompt_str = """
Answer the user question based only on the following context:
{context}
Question: {question}
"""
_prompt = ChatPromptTemplate.from_template(prompt_str)
num_chunks = 3
retriever = qdrant.as_retriever(search_type="similarity", search_kwargs={"k": num_chunks})Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
chat_llm = ChatOpenAI(model_name=llm_name, openai_api_key=openai.api_key, temperature=0)
query_fetcher = itemgetter("question")
setup = {"question": query_fetcher, "context": query_fetcher | retriever | format_docs}
_chain = setup | _prompt | chat_llm | StrOutputParser()

# Create a form for user input
with st.form(key="query_form"):
Â  Â  query = st.text_input("Ask a question about Xeven:", key="user_query")
Â  Â  submit_button = st.form_submit_button(label=" ðŸ’¡ Get Response")Â  # Added submit button

# Process the query if the form is submitted
if submit_button and query:
Â  Â  response = _chain.invoke({"question": query})
Â  Â  st.markdown(f'<div class="response-bubble">Response: {response}</div>', unsafe_allow_html=True)

# Option to clear the chat history
if st.button("ðŸ§¹ Clear History"):
Â  Â  st.session_state['chat_history'] = []
Â  Â  st.success("Chat history cleared!")

st.markdown("---")Â  # Adds a line separator
st.markdown('<div class="footer">Developed by <span class="highlighted-name">Abdul Rehman</span>. Powered by Xeven Solutions.</div>', unsafe_allow_html=True)
